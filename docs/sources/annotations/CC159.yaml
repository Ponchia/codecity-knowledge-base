id: CC159
url: https://news.mit.edu/2024/umwelt-enables-interactive-accessible-charts-creation-blind-low-vision-users-0327
type: website
status: ok
extraction_status: complete
processor: gpt
processed_date: 2026-01-05
summary: |
  Describes Umwelt, MIT/UCL software enabling blind/low-vision users to create
  and consume data through three modalities: visualization, textual description,
  and sonification. Emphasizes de-centering vision as the primary modality.
key_contributions:
  - Multimodal data representation (visual + text + audio)
  - De-centering visualization as just one piece of multisensory experience
  - Automatic heuristics for generating default representations
terms_introduced:
  - multimodal accessibility: "Representing data through multiple modalities (visual, text, audio) that users can switch between"
  - de-centered visualization: "Treating visual representation as one component of a multisensory data experience, not the primary one"
features_described:
  - F078  # accessibility-mode - ENHANCED with multimodal approach
implementations_documented: []
empirical_evidence:
  study_type: user_study
  sample_size: 5
  dependent_variables: [usefulness, exploration_capability, communication]
  independent_variables: [modality]
  key_findings:
    - "Expert screen-reader users found tool useful for creating, exploring, and discussing data"
    - "Valued potential for facilitating communication with sighted colleagues"
  effect_size: null
quality_notes: |
  MIT News 2024, research by Zong, Hajas, Satyanarayan. Complements CC158 with
  emphasis on data creation (not just consumption) and multimodal switching.
statistics:
  features_extracted: 0
  terms_extracted: 2
  implementations_documented: 0
